{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd176c9-71b0-4ebf-99ea-772772e3e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4e929-353b-494a-92cf-add130aa3e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=[\n",
    "    \"A comida estava deliciosa e o atendimento foi impecável.\",\n",
    "    \"Esperei mais de 40 minutos pelo prato principal e veio frio.\",\n",
    "    \"O ambiente é acolhedor, ideal para um jantar romântico.\",\n",
    "    \"Achei os preços altos para a qualidade do que foi servido.\",\n",
    "    \"Melhor risoto que já comi, voltarei com certeza!\",\n",
    "    \"Garçom atencioso, mas a cozinha demorou muito.\",\n",
    "    \"Cardápio criativo e pratos bem apresentados.\",\n",
    "    \"Poucas opções vegetarianas e nenhuma sobremesa vegana.\",\n",
    "    \"Atendimento rápido e ótimo custo-benefício no almoço executivo.\",\n",
    "    \"Lugar barulhento e comida sem tempero. Não recomendo.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3770dff-c734-45e7-b966-aab5e157bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = [\"para para para para teste meu sol\", \"para para gato subiu no sol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5dee92-4c0b-4b05-a694-28d04fe34981",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9840761-f3e5-47f5-b5c4-fb6ba72bd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vectorizer.get_feature_names_out()\n",
    "print(names)\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69277604-391c-479f-b0b6-b51f69ac1ea7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98029a-6a3d-4a93-bcf4-7e11fe2facf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08921a63-987e-4ef2-91af-736b33978538",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e19d64-7956-48b5-a7ff-97179582a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac11dbf5-83fd-405c-87b8-f27ace1e6815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "raw",
   "id": "076100a1-0174-45d4-8364-10b23ef0f37f",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e551879-ae5e-4261-b8b2-9e38719a5136",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034b93b-2da3-40b4-8e65-e8475b730afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tf_idf = TfidfVectorizer(norm=None)\n",
    "tf_idf = vectorizer_tf_idf.fit_transform(toy)\n",
    "names = vectorizer_tf_idf.get_feature_names_out()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573356ac-8c5d-4d75-8b1e-b8d8b28e91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer_tf_idf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8c9bd-a62f-430d-9a8d-ab0b593e3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_words = tf_idf.toarray()\n",
    "tf_idf_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703047e6-1fb8-4337-9453-c44cefdd98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = TfidfVectorizer(norm=None)\n",
    "tf_idf1 = vectorizer1.transform(toy)\n",
    "names = vectorizer1.get_feature_names_out()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da6009e-8956-4aa1-9590-53d5ce2b617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras do vocabulário: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "TF-IDF do primeiro documento: [[0.         1.22314355 1.51082562 1.         0.         0.\n",
      "  1.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "toy = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "vectorizer1 = TfidfVectorizer(norm=None)\n",
    "vectorizer1.fit(toy)  # aprende os termos\n",
    "\n",
    "tf_idf1 = vectorizer1.transform(toy)  # aplica aos documentos\n",
    "\n",
    "names = vectorizer1.get_feature_names_out()\n",
    "print(\"Palavras do vocabulário:\", names)\n",
    "\n",
    "# Visualiza o TF-IDF de todos os termos no primeiro documento\n",
    "print(\"TF-IDF do primeiro documento:\", tf_idf1[0].toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6799b-206d-4f67-b26f-902f13ebfd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()#usa normalização L2, o que deixa os valores entre 0 e 1\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "\n",
    "document = [\"This is the first document\"]\n",
    "tfidf_matrix = tfidf_vectorizer.transform(document)\n",
    "\n",
    "term = \"document\"\n",
    "term_index = tfidf_vectorizer.vocabulary_[term]\n",
    "\n",
    "tfidf_value = tfidf_matrix[0, term_index]\n",
    "\n",
    "print(f\"The TF-IDF value for '{term}' is: {tfidf_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdd71c-8151-497e-849e-73baa96927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: mini buscador\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "tfidf_vectorizer = TfidfVectorizer()#usa normalização L2, o que deixa os valores entre 0 e 1\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "\n",
    "term = \"document\"\n",
    "term_index = tfidf_vectorizer.vocabulary_[term]\n",
    "\n",
    "for i, doc in enumerate(corpus):\n",
    "    tfidf_value = tfidf_vectorizer.transform([doc])[0, term_index]\n",
    "    print(f\"Doc {i+1}: TF-IDF('{term}') = {tfidf_value:.3f}\")\n",
    "\n",
    "#O documento 2 tem o maior peso para \"document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4578897-5e06-4884-b36b-beb3209bbe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Documento  \\\n",
      "0  A comida estava deliciosa e o atendimento foi ...   \n",
      "9  Lugar barulhento e comida sem tempero. Não rec...   \n",
      "1  Esperei mais de 40 minutos pelo prato principa...   \n",
      "2  O ambiente é acolhedor, ideal para um jantar r...   \n",
      "4   Melhor risoto que já comi, voltarei com certeza!   \n",
      "3  Achei os preços altos para a qualidade do que ...   \n",
      "5     Garçom atencioso, mas a cozinha demorou muito.   \n",
      "6       Cardápio criativo e pratos bem apresentados.   \n",
      "7  Poucas opções vegetarianas e nenhuma sobremesa...   \n",
      "8  Atendimento rápido e ótimo custo-benefício no ...   \n",
      "\n",
      "   Relevância para a consulta  \n",
      "0                    0.157374  \n",
      "9                    0.137701  \n",
      "1                    0.000000  \n",
      "2                    0.000000  \n",
      "4                    0.000000  \n",
      "3                    0.000000  \n",
      "5                    0.000000  \n",
      "6                    0.000000  \n",
      "7                    0.000000  \n",
      "8                    0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def buscar_documentos_por_relevancia(corpus, consulta):\n",
    "    \"\"\"\n",
    "    Dado um corpus de documentos e uma string de consulta,\n",
    "    retorna os documentos ordenados por relevância com base em TF-IDF.\n",
    "    \"\"\"\n",
    "    # Cria o vetor TF-IDF com documentos + consulta\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus + [consulta])\n",
    "\n",
    "    # Separa o vetor da consulta (última linha) e os vetores dos documentos\n",
    "    consulta_vector = tfidf_matrix[-1]\n",
    "    document_vectors = tfidf_matrix[:-1]\n",
    "\n",
    "    # Produto escalar como métrica de similaridade (proxy simples de relevância)\n",
    "    similaridades = document_vectors @ consulta_vector.T\n",
    "\n",
    "    # Monta DataFrame com os resultados\n",
    "    ranking_df = pd.DataFrame({\n",
    "        \"Documento\": corpus,\n",
    "        \"Relevância para a consulta\": similaridades.toarray().flatten()\n",
    "    }).sort_values(by=\"Relevância para a consulta\", ascending=False)\n",
    "\n",
    "    return ranking_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Corpus de exemplo (reviews)\n",
    "    corpus = [\n",
    "        \"A comida estava deliciosa e o atendimento foi impecável.\",\n",
    "        \"Esperei mais de 40 minutos pelo prato principal e veio frio.\",\n",
    "        \"O ambiente é acolhedor, ideal para um jantar romântico.\",\n",
    "        \"Achei os preços altos para a qualidade do que foi servido.\",\n",
    "        \"Melhor risoto que já comi, voltarei com certeza!\",\n",
    "        \"Garçom atencioso, mas a cozinha demorou muito.\",\n",
    "        \"Cardápio criativo e pratos bem apresentados.\",\n",
    "        \"Poucas opções vegetarianas e nenhuma sobremesa vegana.\",\n",
    "        \"Atendimento rápido e ótimo custo-benefício no almoço executivo.\",\n",
    "        \"Lugar barulhento e comida sem tempero. Não recomendo.\"\n",
    "    ]\n",
    "\n",
    "    consulta = \"comida fria ruim\"\n",
    "    resultado = buscar_documentos_por_relevancia(corpus, consulta)\n",
    "    print(resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_bag_of_words)",
   "language": "python",
   "name": "env_bag_of_words"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
